{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train data:6025, \n",
      "Length of test data:1507\n",
      "Training data prepared\n",
      "Testing data prepared\n",
      "Preprocessing done\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open(\"./training_data/spacy_training_data.pkl\", \"rb\") as file:\n",
    "    spacy_format_data = pickle.load(file)\n",
    "\n",
    "\n",
    "# Splitting data\n",
    "# Calculate the index to split the data\n",
    "split_index = int(len(spacy_format_data) * 0.80)\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "training_data = spacy_format_data[:split_index]\n",
    "testing_data = spacy_format_data[split_index:]\n",
    "# print(training_data[0])\n",
    "# Check the lengths of the training and testing datasets\n",
    "print(\n",
    "    f\"Length of train data:{len(training_data)}, \\nLength of test data:{len(testing_data)}\"\n",
    ")\n",
    "\n",
    "# the DocBin will store the example documents --train\n",
    "db = DocBin()\n",
    "for sample in training_data:\n",
    "    doc = nlp(sample[0])\n",
    "    entities = []\n",
    "    for start, end, label in sample[1][\"entities\"]:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is not None:\n",
    "            entities.append(span)\n",
    "    doc.ents = entities\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./training_data/train.spacy\")\n",
    "print(\"Training data prepared\")\n",
    "# the DocBin will store the example documents --test\n",
    "db_test = DocBin()\n",
    "for sample in testing_data:\n",
    "    doc = nlp(sample[0])\n",
    "    entities = []\n",
    "    for start, end, label in sample[1][\"entities\"]:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is not None:\n",
    "            entities.append(span)\n",
    "    doc.ents = entities\n",
    "    db_test.add(doc)\n",
    "db_test.to_disk(\"./training_data/test.spacy\")\n",
    "print(\"Testing data prepared\")\n",
    "\n",
    "print(\"Preprocessing done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config.cfg ./config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     45.95    0.00    0.00    0.00    0.00\n",
      "  0     200        406.16   2023.67   99.55   99.23   99.86    1.00\n",
      "  0     400         17.58     88.54   99.91   99.92   99.89    1.00\n",
      "  0     600          2.71      6.28   99.81   99.63   99.99    1.00\n",
      "  0     800         12.37     30.95   99.80   99.99   99.62    1.00\n",
      "  0    1000         89.88    112.59   99.89   99.93   99.85    1.00\n",
      "  0    1200         16.64     17.86   99.99  100.00   99.99    1.00\n",
      "  0    1400          3.24      3.87  100.00  100.00  100.00    1.00\n",
      "  1    1600         33.21     27.72   99.91   99.93   99.88    1.00\n",
      "  1    1800         15.02     11.37   99.99  100.00   99.98    1.00\n",
      "  1    2000         25.70     19.61   99.93   99.93   99.93    1.00\n",
      "  2    2200       6791.91   3401.76   99.99  100.00   99.99    1.00\n",
      "  2    2400         34.75     34.01   99.99  100.00   99.99    1.00\n",
      "  3    2600        192.25     36.26   99.99  100.00   99.99    1.00\n",
      "  3    2800         16.26     10.83  100.00  100.00  100.00    1.00\n",
      "  4    3000          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output --paths.train ./training_data/train.spacy --paths.dev ./training_data/test.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK     100.00\n",
      "NER P   100.00\n",
      "NER R   100.00\n",
      "NER F   100.00\n",
      "SPEED   5073  \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "                              P        R        F\n",
      "PATIENT-ID               100.00   100.00   100.00\n",
      "PATIENT-NAME             100.00   100.00   100.00\n",
      "PATIENT-ADDRESS          100.00   100.00   100.00\n",
      "PATIENT-TYPE             100.00   100.00   100.00\n",
      "PATIENT-DOB              100.00   100.00   100.00\n",
      "PATIENT-GENDER           100.00   100.00   100.00\n",
      "PATIENT-ADMIT-DATE       100.00   100.00   100.00\n",
      "PATIENT-DISCHARGE-DATE   100.00   100.00   100.00\n",
      "PATIENT-DOCID            100.00   100.00   100.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy evaluate ./output/model-best/ ./training_data/test.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING ON ONE SAMPLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word -> P-9877are -------- Label -> PATIENT-ID\n",
      "Word -> Runesh Gazane -------- Label -> PATIENT-NAME\n",
      "Word -> Vanshaj -------- Label -> PATIENT-TYPE\n",
      "Word -> Inp -------- Label -> PATIENT-TYPE\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"./output/model-last/\")\n",
    "\n",
    "if not nlp:\n",
    "    print(\"Model is not loaded...\")\n",
    "else:\n",
    "    text = \"Community General Hospital Patient Account# P-9877are Patient Name Runesh Gazane, Address - Vanshaj, Silver Rd, Pune, Type - Inp\"\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        print(f\"Word -> {ent.text} -------- Label -> {ent.label_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fgvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
